---
title: "Exploring Data Science Education: From Tutorials to Assessment"
subtitle: "Duke Statistical Science | Graduation with Distinction"
date: 2023-04-11
date-format: long
author: 
    - Evan Dragich
    - supervised by Mine Çetinkaya-Rundel, PhD.
format:
  revealjs: 
    slide-number: true
    incremental: true
    preview-links: auto
    logo: images/dukelogo.svg.png
    css: presentation.css
    footer: <https://evandragich.github.io/thesis-work/>
execute: 
  eval: false
  echo: true
embed-resources: true
---

<!-- quarto publish quarto-pub slides/presentation.qmd -->

## About Me

-   Statistical Science B.S. & Psychology B.S.
-   Started StatSci sophomore spring
-   Combination of previous research experiences and interest
    -   STEM education 
    -   TAing Intro Data Science (STA199)

::: notes
I'm a senior double majoring in statsci and Psych.
I had a bit of a roundabout path to the statsci major: I started college premed, wasn't entirely sure what I was doing, but knew I enjoyed STEM and quantitative problem solving. Got involved in research, working on a project possibly slightly out of my depth at the time that required a lot of teaching myself statistics. Realizing I wasn't as interested in the medicine aspects of medicine, more the problem-solving aspects of research, enjoyed statistical aspects more than I thought I would, so made somewhat of a leap of faith and declared statsci major.
Due to making this decision so late, and having solid baseline from Psych major stat classes, AP stat in high school, research experiences, foregoing 199 (intro data science) to unlock higher-level electives earlier. Next semester, became TA for STA 199. Enjoyed thinking about the curriculum and how things were presented, also knew that the Statsci major undergoing some overhaul during my time. Knew I wanted to do an independent study and possibly a thesis at that point, asked Prof. Çetinkaya-Rundel if she had any research projects I could work on, and the rest was history.
:::

## Thesis TOC/Agenda {.smaller}

-   Thesis divided into 2 strands:
    -   Building a introductory data science concept inventory-style assessment
    -   Building `dsbox`, an introductory data science tutorial package
-   Agenda
    -   Background
    -   Initial Steps
    -   Interview Process
    -   Item Case Studies
    -   Package Construction + Examples
    -   Discussion
    -   Q&A
    
::: notes
My overall thesis project consists of two separate, yet related, projects. First, the construction of a concept inventory-style assessment to measure students' learning outcomes in introductory data science classes. Secondly, continuing the themes of introductory data science education and scalability, the construction and release of a package, `dsbox`, which contains 10 standalone tutorials testing similar concepts. those are the two things that are both helpful (they are busy developing own course content), developing tools to help teachers ASSESS their teaching, and the othr is to help teachers SCALE teaching

The structure of my presentation today will be as follows: I will first motivate the need for such an assessment and the process used to develop it. Then, I will quickly discuss the initial steps of my work on the assessment, before taking time to dive into some case studies of several items which form a representative sample of the general iterative process of item creation and refinement.
Then, I'll shift gears to give an overview of the `dsbox` package's goals, structure, and examples from tutorials. Finally, I'll conclude with a reflective discussion before leaving time for questions at the end.
:::

# Building a Data Science Assessment

## Background

-   Concept inventories for educational research
    -   CAOS for statistics
-   Data science (DS) as it emerges as a field--what is it, exactly?
-   How exactly do people: (1) make, (2) pilot, (3) validate new concept inventories or scales?
    
::: notes
Say youre an xyz professor and you want to do research. What do you use to measure? some sort of assessment. Good thing a standardized one exists for calculus, etc. This assessment is most effective if its standard across courses/"validated', gives legimtimcacy to what you do in class, helpful to use as a legit benchmark for your teaching compared to random self-contained assessment. Work on such an assesment for introductory statistics, CAOS, led to paper from 2007 has 418 citations! Clearly this is something people are interested in. We look now to expand that to introductory data science courses--but first, what exactly is data science? As more and more courses and majors emerge, reviews of syllabi have found heavy focuses on computing or pseudocode, data wrangling and visualization, with some focus on statistics, modeling, as well as some smaller ethics component. 
Once a scope has been set and questions drafted, how do we prepare such an assessment for a pilot? Key findings from research on think-aloud interviews has found that testing a variety of questions with specific misconceptions in mind via think-aloud interviews, in which a target population is asked to reason out loud through their thought process. After making refinements based on students' perceptions, assessments are then given at a large scale to collect enough data to test possible subscales. For example, if students' performance on questions on similar topics seemed to be correlated, there is a potential to calculate a separate subscore on that topic, such as data visualization.
Those steps of the process constitute my work on the assessment portion of the thesis, and now I will now dive deeper into each phase of the development.
:::

## Inital cleaning

-   Combine questions into single set of passages and items
-   Draft into Quarto Book for easy browsing

## Inital cleaning

![](images/assessment-book-example.png)

## Interviews

::: notes
-   reminder of what we tried to do (3 faculty to see if scope was appropriate from instructor perspective, 3 TA to see if questions were landing on a closer-to-target population, but still with some DS context)
:::

-   Two rounds of interviews:
    -   3 faculty
    -   3 intro DS teaching assistants
    
## Interviews: Faculty {.smaller}

::: notes
-   still refining scope at this point, so were interested in getting a prior look at what they deemed important.
-    comments and suggestions were small scale (formatting, wording) or large scale (removing question entirely)
-   Summarize results from faculty, and themes (mainly that you could clearly tell the CS prof from the two stats ones via what they thought should be included, things pointed out like uncomfortable contexts (storm paths?)), cognitive load (repeatedd use of "log transformed")
:::

-   Flow:
    -    What topics *must* be in an introductory data science course?
    -    What topics are *nice to have* in an introductory data science course? 
    -    Think-aloud thought process
    -    Additional comments or suggestions
    -    What are the strengths of the current assessment? 
    -    What topics are missing from the current assessment?
    -    What is in the current assessment, but doesn't belong?
-   Themes from faculty interviews
    -   CS vs. Statistics perspectives
    -   Context concerns
    -   Cognitive load
    
## Interviews: Students {.smaller}

::: notes
-   no longer trying to refine scope, so we didnt start with any lead-off questions. did still ask based on their experiences as students in the curriculum
-    we did demonstrate how to "think aloud" with the "how many windows are in your house?" question.
-    in general, students were less verbose with feedback, we solved that somewhat with the think-aloud demonstration, but also showed we were converging on a good prototype.
-    it was interesting to observe a gradient in mastery among those interviewed; they thought more about the questions than faculty and some got more of the trickier ones incorrect as we had thought students might
-    
:::

-   Flow:
    -    Think-aloud thought process
    -    Additional comments or suggestions
    -    Are the pacing and length appropriate? 
    -    Based on what you remember learning in intro data science, what topics are missing from the current assessment? 
    -    Based on what you remember learning in intro data science, what is in the current assessment, but doesn't belong?
-   Themes from student interviews
    -    General agreement
    -    Gradient of mastery


## Current Prototype {.smaller}

-   15 passages, 26 items

::: text-sm
::: fragment
| Passage               | Learning Objective(s)                                                           |
|----------------------|--------------------------------------------------|
| Storm Paths           | modeling; simulation; uncertainty                                               |
| Movie Budgets 1       | compare summary statistics visually                                             |
| Movie Budgets 2       | modeling; $R^2$; compare trends visually                                        |
| Application Screening | ethics; modeling; proxy variable                                                |
| Banana Conclusions    | causation; statistical communication                                            |
| COVID Map             | complex visualization; spatial data; time series; sophisticated scales          |
| He Said She Said      | basic visualization; sophisticated scales                                       |
| Build-a-Plot          | data to visualization process                                                   |
| Disease Screening     | compare classification diagnostics visually                                     |
| Realty Tree           | modeling; regression tree; variable selection                                   |
| Website Testing       | compare trends visually; uncertainty; modeling; time series; extrapolation      |
| Image Recognition     | ethics; modeling; representativeness of training data                           |
| Data Confidentiality  | ethics; data deidentification; statistical communication                        |
| Activity Journal      | structure data; store data                                                      |
| Movie Wrangling       | data cleaning; data wrangling; column-wise string operations; pseudocode; joins |
:::
:::

## Case Study: Application Screening {.smaller}

*You are working on a team that is making a deterministic model to quickly screen through applications for a new position at the company. Based on employment laws, your model may not include variables such as age, race, and gender, which could be potentially discriminatory.*

*Your colleague suggests including a rule that eliminates candidates with more than 20 years of previous work experience, because they may have high salary expectations. Why might using this variable be considered unethical? Explain your answer.*

::: notes
start with AS: a question based on proxy variable.
Oops, best practices would phrase this in a non-leading way. If a student wasn't initially going to think this would be unethical, but we told them it might be somehow, their explanation won't be as valuable as someone who would have answered right away. Okay, let's rephrase to make them answer whether it is or isnt:
:::

## Case Study: Application Screening {.smaller}

*You are working on a team that is making a deterministic model to quickly screen through applications for a new position at the company. Based on employment laws, your model may not include variables such as age, race, and gender, which could be potentially discriminatory.*

*Your colleague suggests including a rule that eliminates candidates with more than 20 years of previous work experience, because they may have high salary expectations.* ***Are there ethical implications of using this variable to select candidates?*** *Explain your answer.*

::: notes
Well... that doesn't help much. We still have the classic selection bias clouding results; students would think "well, if there wasn't an ethical problem, they wouldnt have included this as one of the only ethics questions on the assessment." Plus, how are we grading this? What are we looking for to confirm that they understand the proxy variable? It might work to set up an autograder that marks "correct" if they mark "yes" to the ethics question AND mention "proxy" in their response. But, this is an introductory-level assessment. Will students be able to concisely describe employment expeirence as a "proxy," or would explanations be wordier and might include "is correlated with," "is related to," "goes hand in hand with," "predicts." If we want autogradable, looking like MC is going to be main way to go. Note that, at this stage, Application Screening and several other similar questions are left in open-ended format to collect this type of data from the pilots.
:::

## Case Study: Data Confidentiality {.smaller}

*A newspaper reports on the results of a survey from a small (\<2000 student) college. The college agrees to have the data released to the public so long as the students' identities and academic standing information are kept confidential. Which of the following combinations of variables is less likely to unintentionally identify any students? Explain.*

*a. Year, major, sports played*

*b. Year, major*

::: notes
so, after that whole mess, a general conclusion is that MC might be the only way to go. so how do we write a good MC ethics question? here's a start, with the focus on identifiable data and statistical communication:
Well, first of all, is "college" the best word here? While it's roughly synonymous with "university" in the US, they can have very different meanings country-to-country. Thus, let's eliminate any ambiguity right off the bat.
:::

## Case Study: Data Confidentiality {.smaller}

*A newspaper reports on the results of a survey from a small (\<2000 student)* ***university.*** *The* ***university*** *agrees to have the data released to the public so long as the students' identities and academic standing information are kept confidential. Which of the following combinations of variables is less likely to unintentionally identify any students? Explain.*

*a. Year, major, sports played*

*b. Year, major*

::: notes
Great! There is no issue with grading this on a large scale, as students will simply choose option "a" to be marked correct. But, how valid is this binary comparison of two nearly-identical options in measuring students' idea of data privacy (and key variables whose intersections can quickly narrow down populations). Would they choose "a" simply because of the "presence vs absence" heuristic, similar to the selection bias issue addressed earlier, or because they understand how it quickly narrows down who a respondent could be? This question took a lot of brainstorming and workshopping, and we ultimately landed on the following options:
:::

## Case Study: Data Confidentiality {.smaller}

*A newspaper reports on the results of a survey from a small (\<2000 student) university. The university agrees to have the data released to the public so long as the students' identities and academic standing information are kept confidential. Which of the following combinations of variables is less likely to unintentionally identify any students? Explain.*

***a. Class year and sports played***

***b. Student ID and dorm zip code***

***c. GPA and major***

***d. Birth date and phone number***

***e. None of the above***

::: notes
I really like this current version for a few reasons. First, "none of the above." It doesn't solve everything, but the closest you can get to having an open-ended prompt in a true MC assignment is to have a "none of the above," and to use it! (roughly proportionally, so \~20-25% of the time). Second, the options are well-distributed and take some time to think through. We refined this in the gap between faculty and student interviews, and all three students had a similar response. A nice rhythm as they read through the responses, respectively "hmm, definitely not, ummmm maybe?, yeah definitely not, uh". Immediately eliminating "b" and "d", students debated "a" and "c" on a metric we hadn't even surmised when writing. "Well, in terms of figuring out who people are, class year and sports played would do that. BUT, knowing GPA and major wouldn't really let you identify anyone, but GPA is more sensitive data than class year/sports played in that it would be more harmful if released, and linked back to the people." Out of all the think-aloud interviews, this single moment stood out as justifying why we asked students to walk through their reasoning processes, and to "think out loud:" to catch unexpected thought processes like this.
:::

## Case Study: Movie Budgets 1


::: columns
::: {.column width="30%"}
::: text-sm2
::: {.fragment}
A data scientist at IMDb has been given a dataset comprised of the revenues and budgets for 2,349 movies made between 1986 and 2016.


Suppose they want to compare several distributional features of the budgets among four different genres---Horror, Drama, Action, and Animation. To do this, they create the following plots.
:::
:::
:::

::: {.column width="70%"}
::: {.fragment}
```{r}
#| label: common-R
#| echo: false
#| eval: true

knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  fig.align = "center", 
  out.width = "90%",
  fig.asp = 0.618,
  fig.width = 8
)

library(tidyverse)
library(ggplot2)
library(patchwork)
library(ggridges)
library(knitr)
library(kableExtra)
```

```{r fig.asp=1.1, out.width="75%"}
#| echo: false
#| eval: true
movies <- read_csv("https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv")

# Select subset of movies
genre_list <- c("Action", "Animation", "Drama", "Horror")
set.seed(12345)
movies_2 = movies |>
  filter(genre %in% genre_list, budget > 0, budget < 300000000) |>
  sample_n(n())

# Bar chart
p1 = movies_2 |>
  group_by(genre) |>
  summarise(mean_budget = mean(budget)) |>
  ggplot(aes(x = genre, y = mean_budget, fill = genre)) +
  labs(
    x = "",
    y = "",
    title = "Plot A: Mean budget (in U.S. dollars)"
  ) +
  geom_col(alpha = 0.8, color = "black") +
  scale_y_continuous(labels = scales::dollar_format(accuracy = 1, scale = (1 / 1000000), prefix = "$", suffix = "M"), limits = c(0, 100000000)) +
  scale_fill_manual(
    values = c("#6e7cb9", "#7bbcd5", "#e89c81", "#d2848d") # PNWColors::pnw_palette(name = "Sailboat", n = 4)
  ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")


# Ridge plot
p2 = ggplot(movies_2, aes(x = budget, y = genre, fill = genre)) +
  geom_density_ridges(alpha = 0.8) +
  labs(
    x = "",
    y = "",
    title = "Plot B: Budget (in U.S. dollars)"
  ) +
  scale_x_continuous(labels = scales::dollar_format(accuracy = 1, scale = (1 / 1000000), prefix = "$", suffix = "M"), limits = c(0, 300000000)) +
  scale_fill_manual(
    values = c("#6e7cb9", "#7bbcd5", "#e89c81", "#d2848d") # PNWColors::pnw_palette(name = "Sailboat", n = 4)
  ) +
  theme_bw() +
  theme(legend.position = "none")


# Strip plot
p3 = ggplot(data = movies_2, aes(x = genre, y = budget, fill = genre)) +
  geom_point(alpha = 0.8, color = "black", pch = 21) +
  labs(
    x = "",
    y = "",
    title = "Plot C: Budget (in U.S. dollars)"
  ) +
  scale_y_continuous(labels = scales::dollar_format(accuracy = 1, scale = (1 / 1000000), prefix = "$", suffix = "M"), limits = c(0, 300000000)) +
  scale_fill_manual(
    values = c("#6e7cb9", "#7bbcd5", "#e89c81", "#d2848d") # PNWColors::pnw_palette(name = "Sailboat", n = 4)
  ) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_flip()


p4 = ggplot(data = movies_2, aes(x = genre, y = budget, fill = genre)) +
  geom_boxplot(alpha = 0.8, color = "black") +
  labs(
    x = "",
    y = "",
    title = "Plot D: Budget (in U.S. dollars)"
  ) +
  scale_y_continuous(labels = scales::dollar_format(accuracy = 1, scale = (1 / 1000000), prefix = "$", suffix = "M"), limits = c(0, 300000000)) +
  scale_fill_manual(
    values = c("#6e7cb9", "#7bbcd5", "#e89c81", "#d2848d") # PNWColors::pnw_palette(name = "Sailboat", n = 4)
  ) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_flip()


# Layout plots
p1 / p2 / p3 / p4
```
:::
:::
:::

::: notes
we iterated over a variety of statistics, such as outliers, skewness, mode, variance, and number of observations. We ultimately landed on these because we think it strikes an appropriate balance as a pre- and post-test. However, note that grading matrices like this is slightly more complex than simple multiple choice questions. Should each checkbox be considered one question, weighting this the same as 16 other items? (half the assessment). Or, 1/16th of a point each? so missing half is only half a point off? This is the kind of thing observing large-scale student trends will be helpful for, to see if there are any critical distinctions that separate discrete stratifications of students
:::

## Case Study: Movie Budgets 1

Fill in the following table by placing a check mark in the cells corresponding to the attributes of the data that can be determined by examining each of the plots.

|        | Plot A | Plot B | Plot C | Plot D |
|--------|--------|--------|--------|--------|
| Mean   | ☐      | ☐      | ☐      | ☐      |
| Median | ☐      | ☐      | ☐      | ☐      |
| IQR    | ☐      | ☐      | ☐      | ☐      |
| Shape  | ☐      | ☐      | ☐      | ☐      |

## Case Study: Movie Wrangling

The table below provides data about 10 movies released in the United States. It provides data on the movie's title , the movie's director, the date the movie was released, the season the movie was released, the worldwide gross intake in U.S. dollars, the cleaned version of the worldwide gross intake in U.S. dollars, and whether or not the movie won the Best Picture Oscar.


## Case Study: Movie Wrangling

::: text-sm5
```{r}
#| eval: true
#| echo: false
movie_table <- read_csv("data/movie-table.csv")
directors_table <- read_csv("data/directors-table.csv")

kable(movie_table,
  #align = "l",
  caption = "Movies Table",
  booktabs = FALSE,
  ) #|>
  # kable_styling(latex_options = c("striped", "scale_down"),
  #               html_font = '"Courier"',
  #               font_size = 12) |>
  # row_spec(0, bold = TRUE)
```
:::

## Case Study: Movie Wrangling

::: notes
if theres time to flash the code one, another challenge was asking somethign aobut computation (whcih is important) but in a language agnostic way. based on time, wont be going through how we came up with it, but this is a fake computing language but same time you can do it.
:::

::: {.columns}

::: {.column width="30%"}
::: text-sm4
The table below provides data about 10 movie directors. It provides data on the director's name, the number of Oscars the movie's director has been nominated for, and the number of Oscars the director has won.
:::
:::

::: {.column width="70%"}
::: text-sm3
```{r}
#| eval: true
#| echo: false
kable(directors_table,
  #align = "l",
  caption = "Directors Table",
  booktabs = FALSE,
  ) #|>
  # kable_styling(latex_options = c("striped", "HOLD_position"),
  #               html_font = '"Courier"',
  #               font_size = 12) |>
  # row_spec(0, bold = TRUE)
```
:::
:::
:::

## Assessment Next Steps

-   199 Pilot
-   IRB Roadblocks
-   NSF Grant

::: notes
Turn into more robust JS framework like CAOS is
:::

# Working on the `dsbox` package

## `dsbox` package

-   Growing interest in DS requires scalability

-   Data Science in a Box project

-   Turning it into `dsbox`

::: notes
one strand of thesis is developing tools to help instructors ASSESS teaching, and the other is to help teachers SCALE teaching. that plus the opensource nature of R lends naturally to making such a standardized curriculum

What is Data Science in a Box? Its that \^. Using `tidyverse` to practice basic data wrangling, visualization, and modeling.

That curriculum set was then condensed into a package for self-learners called `dsbox`, which users can download and follow to become well-acquainted with basic data science in R.
:::

## How does it work?

-   2 key packages: `learnr` and `gradethis`.

-   `learnr`: robust, broad framework.

-   `gradethis`: sophisticated testing logic.

::: notes
`learnr` provides a robust framework for turning RMarkdown documents into interactive tutorials, where users can be guided through running and writing code, quiz questions, watching videos, etc, directly in the "Tutorial" pane in RStudio. A key feature is that progress is saved, so you can resume working in RStudio whenever

`gradethis` takes that basic, broad framework, and provides tools for drilling down deeper when grading. Instructors can provide feedback for a variety of common mistakes with 
:::

## Creating a Tutorial

-  9 existing, 1 started

-  Modifying for interactive tutorial

    -   Scaffolding, clear section breaks, engaging flow
    
::: notes
(these corresponded to all HWs from DSinaBox; the package had skeleton .Rd files for the dataset already).
Decided I would try to recreate that tutorial, adding in some flair and thoughts based on best practices,
so i expanded more on one of the exercises more to match the "interactive tutorial" modality vs the "take home, class homework assignment"
:::

## Sample Tutorial: Home Page

![](images/00-main-menu.png){.absolute bottom="0" left="300" height="600"}

## Sample Tutorial: Code chunk with hint

![](images/03-hint.png){.absolute bottom="0" left="250" height="600"}

## Sample Tutorial: Opening the hood

::: {.absolute bottom="480" left="300"}
::: fragment
````         
```{r common-themes, exercise = TRUE}`r ''`
lego_sales |>
  ___(___)
```
````
:::
:::

::: {.absolute bottom="290" left="300"}
::: fragment
````         
```{r common-themes-hint-1}`r ''`
Look at the previous question for help!
```
````
:::
:::

::: {.absolute bottom="90" left="300"}
::: fragment
````         
```{r common-themes-solution}`r ''`
lego_sales |>
  count(theme, sort = TRUE)
```
````
:::
:::

## Sample Tutorial: Opening the hood

::: {.absolute bottom="0" left="100"}
::: fragment
```         
```{r common-themes-check}`r ''`
grade_this({
  if(identical(as.character(.result[1,1]), "Star Wars")) {
    pass("You have counted themes and sorted the counts correctly.")
  }
  if(identical(as.character(.result[1,1]), "Advanced Models ")) {
    fail("Did you forget to sort the counts in descending order?")
  }
  if(identical(as.character(.result[1,1]), "Classic")) {
    fail("Did you accidentally sort the counts in ascending order?")
  }
```

````         
  if(identical(as.character(.result[1,1]), "Adventure Camp")) {
    fail("Did you count subthemes instead of themes?")
  }
  if(identical(as.numeric(.result[1,2]), 172)) {
    fail("Did you count subthemes instead of themes?")
  }
  fail("Not quite. Take a peek at the hint!")
})
```
````
:::
:::

## Releasing to CRAN

-   Comprehensive R Archive Network

-   Package DESCRIPTION file

-   `gradethis` still in development

::: notes
explain what CRAN is/stands for,
explain what the DESCRIPTION folder is and how we have to check for dependencies.
Unfortunately, `gradethis` is still in development and thus not yet released on CRAN itself. In turn, we are unable to upload a package that specifies a package not on CRAN to be one of its dependencies. We have submitted an issue
:::

# Discussion

## Learning Takeaways

-   Advanced computing

-   Interacting with others' code

::: notes
 advanced computing I wouldn't have gotten otherwise in my abbreviated trip through the Stat major (all sorts of HTML, CSS, ins and outs of R, Quarto, Shiny)
 Learned how to interact with others' code beyond scope of classroom/research team (making and reviewing public PR requests, compiling and standardizing and revising the assessment and package)
:::

## Reflections

-   "Teaching material is only way to master it"

-   New appreciation for existing educational materials and research

-   Inspired me to continue interacting with the world of open source software 

::: notes
Statement that "teaching material is only way to master it" had always been true for my tutoring and TAing experiences; developing and studying a curriculum to the point of scrutiny took my understanding to the next level. 

Newfound appreciation for work that has gone into all the educational curriculum materials today, tools like `ghclass` and `learnr`, all packages that have been released and are maintained and what it takes to do that. as well, working with a collaboration where everyone is interested in education but has different areas of expertise 

Inspired me to continue interacting with the world of open source software even though my job (for the meantime) is to be an Excel monkey for 40 hours a week
:::

## Q&A

::: nonincremental
-   Browse at your own pace at <https://evandragich.github.io/thesis-work/>

-   Email me at [emd48\@duke.edu](mailto:emd48@duke.edu)
:::

::: footer
:::
