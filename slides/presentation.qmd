---
title: "Exploring Data Science Education: From Tutorials to Assessment"
subtitle: "Duke Statistical Science | Graduation with Distinction"
date: 2023-04-11
date-format: long
author: 
    - Evan Dragich
    - supervised by Mine Çetinkaya-Rundel, PhD.
format:
  revealjs: 
    slide-number: true
    incremental: true
    preview-links: auto
    logo: images/dukelogo.svg.png
    css: presentation.css
    footer: <https://evandragich.github.io/thesis-work/>
execute: 
  eval: false
  echo: true
embed-resources: true
---

<!-- quarto publish quarto-pub slides/presentation.qmd -->

## Introduction/ About Me

-   Basic demographic background information
-   How i found myself in Duke StatSci (leads into)
-   How i found myself working on this thesis

## Agenda/Thesis TOC

-   explanation of the 2 strands
-   summary of following slides (and stuff like there will be time for questions, etc.)

# Building a Data Science Assessment

## Background

-   Colloquially motivate the need for a DS concept inventory
    -   CAOS, has 418 citations!
-   Data Science as it emerges as a field--what is it, exactly?
    -   colloquially explain Cetinkaya Rundel/Ellison and Zhang/Zhang findings.
-   How exactly do people: (1) make, (2) pilot, (3) validate new concept inventories or scales?
    -   colloquially explain Jorion papers

## Inital cleaning/getting my feet wet

-   Should i even present on this? Is any of it interesting/worth diving into?

## Interviews

-   reminder of what we tried to do (3 faculty to see if scope was appropriate from instructor perspective, 3 TA to see if questions were landing on a closer-to-target population, but still with some DS context)
-   Summarize results from faculty, and themes (mainly that you could clearly tell the CS prof from the two stats ones via what they thought should be included, things pointed out like uncomfortable contexts (storm paths?))

## Current Prototype {.smaller}

-   15 passages, 26 items

::: text-sm
::: fragment
| Passage               | Learning Objective(s)                                                           |
|----------------------|--------------------------------------------------|
| Storm Paths           | modeling; simulation; uncertainty                                               |
| Movie Budgets 1       | compare summary statistics visually                                             |
| Movie Budgets 2       | modeling; $R^2$; compare trends visually                                        |
| Application Screening | ethics; modeling; proxy variable                                                |
| Banana Conclusions    | causation; statistical communication                                            |
| COVID Map             | complex visualization; spatial data; time series; sophisticated scales          |
| He Said She Said      | basic visualization; sophisticated scales                                       |
| Build-a-Plot          | data to visualization process                                                   |
| Disease Screening     | compare classification diagnostics visually                                     |
| Realty Tree           | modeling; regression tree; variable selection                                   |
| Website Testing       | compare trends visually; uncertainty; modeling; time series; extrapolation      |
| Image Recognition     | ethics; modeling; representativeness of training data                           |
| Data Confidentiality  | ethics; data deidentification; statistical communication                        |
| Activity Journal      | structure data; store data                                                      |
| Movie Wrangling       | data cleaning; data wrangling; column-wise string operations; pseudocode; joins |
:::
:::

## Case Study: Application Screening {.smaller}

start with AS: a question based on proxy variable.

*You are working on a team that is making a deterministic model to quickly screen through applications for a new position at the company. Based on employment laws, your model may not include variables such as age, race, and gender, which could be potentially discriminatory.*

*Your colleague suggests including a rule that eliminates candidates with more than 20 years of previous work experience, because they may have high salary expectations. Why might using this variable be considered unethical? Explain your answer.*

Oops, best practices would phrase this in a non-leading way. If a student wasn't initially going to think this would be unethical, but we told them it might be somehow, their explanation won't be as valuable as someone who would have answered right away. Okay, let's rephrase to make them answer whether it is or isnt:

## Case Study: Application Screening {.smaller}

*You are working on a team that is making a deterministic model to quickly screen through applications for a new position at the company. Based on employment laws, your model may not include variables such as age, race, and gender, which could be potentially discriminatory.*

*Your colleague suggests including a rule that eliminates candidates with more than 20 years of previous work experience, because they may have high salary expectations.* ***Are there ethical implications of using this variable to select candidates?*** *Explain your answer.*

Well... that doesn't help much. We still have the classic selection bias clouding results; students would think "well, if there wasn't an ethical problem, they wouldnt have included this as one of the only ethics questions on the assessment." Plus, how are we grading this? What are we looking for to confirm that they understand the proxy variable? It might work to set up an autograder that marks "correct" if they mark "yes" to the ethics question AND mention "proxy" in their response. But, this is an introductory-level assessment. Will students be able to concisely describe employment expeirence as a "proxy," or would explanations be wordier and might include "is correlated with," "is related to," "goes hand in hand with," "predicts." If we want autogradable, looking like MC is going to be main way to go. Note that, at this stage, Application Screening and several other similar questions are left in open-ended format to collect this type of data from the pilots.

## Case Study: Data Confidentiality {.smaller}

so, after that whole mess, a general conclusion is that MC might be the only way to go. so how do we write a good MC ethics question? here's a start, with the focus on identifiable data and statistical communication:

*A newspaper reports on the results of a survey from a small (\<2000 student) college. The college agrees to have the data released to the public so long as the students' identities and academic standing information are kept confidential. Which of the following combinations of variables is less likely to unintentionally identify any students? Explain.*

*a. Year, major, sports played*

*b. Year, major*

Well, first of all, is "college" the best word here? While it's roughly synonymous with "university" in the US, they can have very different meanings country-to-country. Thus, let's eliminate any ambiguity right off the bat.

## Case Study: Data Confidentiality {.smaller}

*A newspaper reports on the results of a survey from a small (\<2000 student)* ***university.*** *The* ***university*** *agrees to have the data released to the public so long as the students' identities and academic standing information are kept confidential. Which of the following combinations of variables is less likely to unintentionally identify any students? Explain.*

*a. Year, major, sports played*

*b. Year, major*

Great! There is no issue with grading this on a large scale, as students will simply choose option "a" to be marked correct. But, how valid is this binary comparison of two nearly-identical options in measuring students' idea of data privacy (and key variables whose intersections can quickly narrow down populations). Would they choose "a" simply because of the "presence vs absence" heuristic, similar to the selection bias issue addressed earlier, or because they understand how it quickly narrows down who a respondent could be? This question took a lot of brainstorming and workshopping, and we ultimately landed on the following options:

## Case Study: Data Confidentiality {.smaller}

*A newspaper reports on the results of a survey from a small (\<2000 student) university. The university agrees to have the data released to the public so long as the students' identities and academic standing information are kept confidential. Which of the following combinations of variables is less likely to unintentionally identify any students? Explain.*

***a. Class year and sports played***

***b. Student ID and dorm zip code***

***c. GPA and major***

***d. Birth date and phone number***

***e. None of the above***

::: notes
I really like this current version for a few reasons. First, "none of the above." It doesn't solve everything, but the closest you can get to having an open-ended prompt in a true MC assignment is to have a "none of the above," and to use it! (roughly proportionally, so \~20-25% of the time). Second, the options are well-distributed and take some time to think through. We refined this in the gap between faculty and student interviews, and all three students had a similar response. A nice rhythm as they read through the responses, respectively "hmm, definitely not, ummmm maybe?, yeah definitely not, uh". Immediately eliminating "b" and "d", students debated "a" and "c" on a metric we hadn't even surmised when writing. "Well, in terms of figuring out who people are, class year and sports played would do that. BUT, knowing GPA and major wouldn't really let you identify anyone, but GPA is more sensitive data than class year/sports played in that it would be more harmful if released, and linked back to the people." Out of all the think-aloud interviews, this single moment stood out as justifying why we asked students to walk through their reasoning processes, and to "think out loud:" to catch unexpected thought processes like this.
:::

## Case Study: Movie Budgets 1


::: columns
::: {.column width="30%"}
::: text-sm2
::: {.fragment}
A data scientist at IMDb has been given a dataset comprised of the revenues and budgets for 2,349 movies made between 1986 and 2016.


Suppose they want to compare several distributional features of the budgets among four different genres---Horror, Drama, Action, and Animation. To do this, they create the following plots.
:::
:::
:::

::: {.column width="70%"}
::: {.fragment}
```{r}
#| label: common-R
#| echo: false
#| eval: true

knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  fig.align = "center", 
  out.width = "90%",
  fig.asp = 0.618,
  fig.width = 8
)

library(tidyverse)
library(ggplot2)
library(patchwork)
library(ggridges)
library(knitr)
library(kableExtra)
```

```{r fig.asp=1.1, out.width="80%"}
#| echo: false
#| eval: true
movies <- read_csv("https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv")

# Select subset of movies
genre_list <- c("Action", "Animation", "Drama", "Horror")
set.seed(12345)
movies_2 = movies |>
  filter(genre %in% genre_list, budget > 0, budget < 300000000) |>
  sample_n(n())

# Bar chart
p1 = movies_2 |>
  group_by(genre) |>
  summarise(mean_budget = mean(budget)) |>
  ggplot(aes(x = genre, y = mean_budget, fill = genre)) +
  labs(
    x = "",
    y = "",
    title = "Plot A: Mean budget (in U.S. dollars)"
  ) +
  geom_col(alpha = 0.8, color = "black") +
  scale_y_continuous(labels = scales::dollar_format(accuracy = 1, scale = (1 / 1000000), prefix = "$", suffix = "M"), limits = c(0, 100000000)) +
  scale_fill_manual(
    values = c("#6e7cb9", "#7bbcd5", "#e89c81", "#d2848d") # PNWColors::pnw_palette(name = "Sailboat", n = 4)
  ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = "none")


# Ridge plot
p2 = ggplot(movies_2, aes(x = budget, y = genre, fill = genre)) +
  geom_density_ridges(alpha = 0.8) +
  labs(
    x = "",
    y = "",
    title = "Plot B: Budget (in U.S. dollars)"
  ) +
  scale_x_continuous(labels = scales::dollar_format(accuracy = 1, scale = (1 / 1000000), prefix = "$", suffix = "M"), limits = c(0, 300000000)) +
  scale_fill_manual(
    values = c("#6e7cb9", "#7bbcd5", "#e89c81", "#d2848d") # PNWColors::pnw_palette(name = "Sailboat", n = 4)
  ) +
  theme_bw() +
  theme(legend.position = "none")


# Strip plot
p3 = ggplot(data = movies_2, aes(x = genre, y = budget, fill = genre)) +
  geom_point(alpha = 0.8, color = "black", pch = 21) +
  labs(
    x = "",
    y = "",
    title = "Plot C: Budget (in U.S. dollars)"
  ) +
  scale_y_continuous(labels = scales::dollar_format(accuracy = 1, scale = (1 / 1000000), prefix = "$", suffix = "M"), limits = c(0, 300000000)) +
  scale_fill_manual(
    values = c("#6e7cb9", "#7bbcd5", "#e89c81", "#d2848d") # PNWColors::pnw_palette(name = "Sailboat", n = 4)
  ) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_flip()


p4 = ggplot(data = movies_2, aes(x = genre, y = budget, fill = genre)) +
  geom_boxplot(alpha = 0.8, color = "black") +
  labs(
    x = "",
    y = "",
    title = "Plot D: Budget (in U.S. dollars)"
  ) +
  scale_y_continuous(labels = scales::dollar_format(accuracy = 1, scale = (1 / 1000000), prefix = "$", suffix = "M"), limits = c(0, 300000000)) +
  scale_fill_manual(
    values = c("#6e7cb9", "#7bbcd5", "#e89c81", "#d2848d") # PNWColors::pnw_palette(name = "Sailboat", n = 4)
  ) +
  theme_bw() +
  theme(legend.position = "none") +
  coord_flip()


# Layout plots
p1 / p2 / p3 / p4
```
:::
:::
:::

::: notes
we iterated over a variety of statistics, such as outliers, skewness, mode, variance, and number of observations. We ultimately landed on these because we think it strikes an appropriate balance as a pre- and post-test. However, note that grading matrices like this is slightly more complex than simple multiple choice questions. Should each checkbox be considered one question, weighting this the same as 16 other items? (half the assessment). Or, 1/16th of a point each? so missing half is only half a point off? This is the kind of thing observing large-scale student trends will be helpful for, to see if there are any critical distinctions that separate discrete stratifications of students
:::

## Case Study: Movie Budgets 1

Fill in the following table by placing a check mark in the cells corresponding to the attributes of the data that can be determined by examining each of the plots.

|        | Plot A | Plot B | Plot C | Plot D |
|--------|--------|--------|--------|--------|
| Mean   | ☐      | ☐      | ☐      | ☐      |
| Median | ☐      | ☐      | ☐      | ☐      |
| IQR    | ☐      | ☐      | ☐      | ☐      |
| Shape  | ☐      | ☐      | ☐      | ☐      |

## Case Study: Movie Wrangling

The table below provides data about 10 movies released in the United States. It provides data on the movie's title , the movie's director, the date the movie was released, the season the movie was released, the worldwide gross intake in U.S. dollars, the cleaned version of the worldwide gross intake in U.S. dollars, and whether or not the movie won the Best Picture Oscar.


## Case Study: Movie Wrangling

::: text-sm5
```{r}
#| eval: true
#| echo: false
movie_table <- read_csv("data/movie-table.csv")
directors_table <- read_csv("data/directors-table.csv")

kable(movie_table,
  #align = "l",
  caption = "Movies Table",
  booktabs = FALSE,
  ) #|>
  # kable_styling(latex_options = c("striped", "scale_down"),
  #               html_font = '"Courier"',
  #               font_size = 12) |>
  # row_spec(0, bold = TRUE)
```
:::

## Case Study: Movie Wrangling

::: notes
hit the idea of pre vs post appropriacy. anything with graphs. maybe the matrix movie budgets. if theres time to flash the code one, another challenge was asking somethign aobut computation (whcih is important) but in a language agnostic way. based on time, wont be going through how we came up with it, but this is a fake computing language but same time you can do it.
:::

::: {.columns}

::: {.column width="30%"}
::: text-sm4
The table below provides data about 10 movie directors. It provides data on the director's name, the number of Oscars the movie's director has been nominated for, and the number of Oscars the director has won.
:::
:::

::: {.column width="70%"}
::: text-sm3
```{r}
#| eval: true
#| echo: false
kable(directors_table,
  #align = "l",
  caption = "Directors Table",
  booktabs = FALSE,
  ) #|>
  # kable_styling(latex_options = c("striped", "HOLD_position"),
  #               html_font = '"Courier"',
  #               font_size = 12) |>
  # row_spec(0, bold = TRUE)
```
:::
:::
:::

## Assessment Next Steps

-   199 Pilot
-   IRB Roadblocks
-   NSF Grant?
    -   Turn into more robust JS framework like CAOS is

# Working on the `dsbox` package

## `dsbox` package {.smaller}

-   Reference growing DS interest and scalability of education from the assessment talk earlier; that plus the opensource nature of R lends naturally to making such a standardized curriculum

-   What is Data Science in a Box? Its that \^. Using `tidyverse` to practice basic data wrangling, visualization, and modeling.

-   That curriculum set was then condensed into a package for self-learners called `dsbox`, which users can download and follow to become well-acquainted with basic data science in R.

## How does it work? {.smaller}

-   2 key packages: `learnr` and `gradethis`.

-   `learnr` provides a robust framework for turning RMarkdown documents into interactive tutorials, where users can be guided through running and writing code, quiz questions, watching videos, etc, directly in the "Tutorial" pane in RStudio. A key feature is that progress is saved, so you can resume working in RStudio whenever.

-   `gradethis` takes that basic, broad framework, and provides tools for drilling down deeper when grading. Instructors can provide feedback for a variety of common mistakes with sophisticated testing logic.

## Creating a Tutorial

-   9 existing, skeleton for 1 (these corresponded to all HWs from DSinaBox; the package had skeleton .Rd files for the dataset already).

-   Decided I would try to recreate that tutorial, adding in some flair and thoughts based on best practices

    -   scaffolded one of the exercises more to match the "interactive tutorial" modality vs the "take home, class homework assignment"

## Sample Tutorial: Home Page

![](images/00-main-menu.png){.absolute bottom="0" left="300" height="600"}

## Sample Tutorial: Code chunk with hint

![](images/03-hint.png){.absolute bottom="0" left="250" height="600"}

## Sample Tutorial: Opening the hood

::: {.absolute bottom="480" left="300"}
::: fragment
````         
```{r common-themes, exercise = TRUE}`r ''`
lego_sales |>
  ___(___)
```
````
:::
:::

::: {.absolute bottom="290" left="300"}
::: fragment
````         
```{r common-themes-hint-1}`r ''`
Look at the previous question for help!
```
````
:::
:::

::: {.absolute bottom="90" left="300"}
::: fragment
````         
```{r common-themes-solution}`r ''`
lego_sales |>
  count(theme, sort = TRUE)
```
````
:::
:::

## Sample Tutorial: Opening the hood

::: {.absolute bottom="0" left="100"}
::: fragment
```         
```{r common-themes-check}`r ''`
grade_this({
  if(identical(as.character(.result[1,1]), "Star Wars")) {
    pass("You have counted themes and sorted the counts correctly.")
  }
  if(identical(as.character(.result[1,1]), "Advanced Models ")) {
    fail("Did you forget to sort the counts in descending order?")
  }
  if(identical(as.character(.result[1,1]), "Classic")) {
    fail("Did you accidentally sort the counts in ascending order?")
  }
```

````         
  if(identical(as.character(.result[1,1]), "Adventure Camp")) {
    fail("Did you count subthemes instead of themes?")
  }
  if(identical(as.numeric(.result[1,2]), 172)) {
    fail("Did you count subthemes instead of themes?")
  }
  fail("Not quite. Take a peek at the hint!")
})
```
````
:::
:::

## Releasing to CRAN

-   Explaining what CRAN is

-   Explaining what the DESCRIPTION folder and dependencies are

-   Unfortunately, `gradethis` is still in development and thus not yet released on CRAN itself. In turn, we are unable to upload a package that specifies a package not on CRAN to be one of its dependencies. We have submitted an issue

# Discussion

## Learning Takeaways

-   Learned advanced computing I wouldn't have gotten otherwise in my abbreviated trip through the Stat major

-   Learned how to interact with others' code beyond scope of classroom/research team (making and reviewing public PR requests, compiling and standardizing and revising the assessment and package)

## Reflections

-   Statement that "teaching material is only way to master it" had always been true for my tutoring and TAing experiences; developing and studying a curriculum to the point of scrutiny took my understanding to the next level

-   Newfound appreciation for work that has gone into all the educational curriculum materials today, tools like `ghclass` and `learnr`, all packages that have been released and are maintained and what it takes to do that.

-   Inspired me to continue interacting with the world of open source software even though my job (for the meantime) is to be an Excel monkey for 40 hours a week

## Q&A

::: nonincremental
-   Browse at your own pace at <https://evandragich.github.io/thesis-work/>

-   Email me at [emd48\@duke.edu](mailto:emd48@duke.edu)
:::

::: footer
:::
