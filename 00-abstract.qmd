---
title: "00-abstract"
author: "Evan Dragich"
format: pdf
from: markdown+emoji
editor: source
---

### Presentation Title: \*

Creating a standardized assessment to measure learning in introductory data science courses

### Presentation Type: \*

:ballot_box_with_check: **Poster**

For Posters, describe the teaching environment (e.g., type of institution, type of students, number of students per class), what takeaways viewers of the poster should expect, and whether the work has IRB approval. It is helpful, but not necessary, for those submitting posters to have some citations to support their work.

Beyond

For "Beyond", provide a description of the activity, demonstration, applet, etc., if possible and describe how you incorporate the demonstration, activity, or method into your classroom, and how you assess (formative or summative) the demonstration. Provide a brief description of the teaching environment (e.g., type of class, number of students, etc.) in which you use the activity. For Beyond submission, the committee will be looking at potential for efficacy, but formal evidence is not necessary.

### Brief Abstract: \*

200 words remaining.

223 words:

As data science continues to grow in popularity among university course offerings, it is becoming crucial to successfully measure students' learning outcomes in introductory courses. While no two introductory "data science" courses are alike, many draw from a similar blend of computer science and statistics backgrounds and a focus on data visualization and ethics to best orient students for today's data-driven world. Thus, a standardized assessment designed to compare pedagogical techniques or curriculum interventions is needed.

A multi-institution team of statistics and data science education researchers began by examining syllabi for introductory data science courses and arriving at a list of topics, such as data wrangling, introductory statistics, and interpreting visualizations. After writing \~50 questions to measure these concepts, a draft assessment in Quarto was used to conduct 3 think-aloud interviews with field-relevant faculty members. The interviews consisted of both open-ended brainstorming on the assessment's scope as well as individual examinations of each item for relevance, clarity, and efficacy in measuring the desired learning objective.

Here we present the current assessment, a set of 36 language-agnostic items measuring students' quantitative literacy at a level appropriate for a pre-test to an introductory class. Looking ahead, the team will conduct interview with undergraduate students who are TAing an intro course similar to the style of the assessment before conducting true pilot tests with live students.

### Goals: \*

150 words remaining.

Briefly describe what you hope participants will take away from your poster or beyond submission. If appropriate, comment on how the topic connects to the theme of "Communicating with/about Data"

### Permissions: \*

Do you have the appropriate permissions to share the data included with your poster (e.g., IRB, intellectual property)?

:ballot_box_with_check: **Yes**

No

Pending

Not Applicable
