[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring Data Science Education: From Tutorials to Assessment",
    "section": "",
    "text": "Abstract\n\nPresentation Title: *\nCreating a standardized assessment to measure learning in introductory data science courses\n\n\nBrief Abstract:\nAs data science (DS) continues to grow in popularity among university course offerings, it is becoming crucial to successfully measure students’ learning outcomes in introductory courses. To do this requires an assessment designed to which could additionally be used to evaluate pedagogical techniques or curriculum interventions in data science curriculum\nTo develop a blueprint for the assessment, a multi-institutional team of statistics and data science education researchers identified common DS content (e.g., data wrangling, interpreting visualizations), drawing from published guidelines/recommendations and introductory DS syllabi. A draft of the assessment was written and used to conduct three think-aloud interviews with field-relevant faculty members.The interviews consisted of both open-ended brainstorming on the assessment’s scope as well as individual examinations of each item for relevance, clarity, and efficacy in measuring the desired learning objective. Think-aloud interviews were also conducted with introductory DS students to gauge item clarity and gain insight into the reasoning for their responses.\nThis poster includes the blueprint developed, as well as example items, and results from the faculty and student think aloud interviews. We also present next steps for the project including plans for larger scale piloting and further analyses.\n\n\nGoals\nBy sharing the work, we hope that participants will become familiar with an assessment they may use for designing intro data science curriculum or researching classroom innovations. We also hope that this instrument can serve as an inspiration or a starting point to be tailored by future researchers more specifically to their courses or to another discipline (eg. by adding more programming concepts instead of data visualization to better serve a computing-focused introductory data science class, etc.)\n\n\n\n\nÇetinkaya-Rundel, Mine, and Victoria Ellison. 2021. “A Fresh Look at Introductory Data Science.” Journal of Statistics and Data Science Education 29 (sup1): S16–26.\n\n\nDelmas, Robert, Joan Garfield, Ann Ooms, and Beth Chance. 2007. “ASSESSING STUDENTS’ CONCEPTUAL UNDERSTANDING AFTER A FIRST COURSE IN STATISTICS.” STATISTICS EDUCATION RESEARCH JOURNAL 6 (2): 28–58.\n\n\nEpstein, Jerome. 2013. “The Calculus Concept Inventory-Measurement of the Effect of Teaching Methodology in Mathematics.” Notices of the American Mathematical Society 60 (8): 1018–27.\n\n\nGodfrey, Kelly E., and Sanja Jagesic. 2016. Validating College Course Placement Decisions Based on CLEP Exam Scores: CLEP Placement Validity Study Results. Statistical Report. College Board.\n\n\nMulford, DouglasRobert. 1996. “An Inventory for Measuring College Students’ Level of Misconceptions in First Semester Chemistry.” Unpublished Master’s Thesis, Purdue University, IN.\n\n\nSolomon, Erin D., Julie M. Bugg, Shaina F. Rowell, Mark A. McDaniel, Regina F. Frey, and Paul S. Mattson. 2021. “Development and Validation of an Introductory Psychology Knowledge Inventory.” Scholarship of Teaching and Learning in Psychology 7: 123–39.\n\n\nSwanstrom, Ryan. n.d. “Data Science Colleges and Universities.” http://datascience.community/colleges.\n\n\nZhang, Zhiyong, and Danyang Zhang. 2021. “What Is Data Science? An Operational Definition Based on Text Mining of Data Science Curricula.” Journal of Behavioral Data Science 1 (1): 1–16."
  }
]